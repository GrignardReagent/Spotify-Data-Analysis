@misc{spotify_statistics,
  author = {RouteNote},
  title = {Share of music streaming subscribers worldwide in the 2nd quarter of 2022, by company},
  year = {2022},
  howpublished = {https://www-statista-com.ezproxy.is.ed.ac.uk/statistics/653926/music-streaming-service-subscriber-share/},
  note = {[Accessed 31-10-2023]}
}

@misc{spotifySpotifyDevelopers,
	author = {},
	title = {{W}eb {A}{P}{I} | {S}potify for {D}evelopers --- developer.spotify.com},
	howpublished = {\url{https://developer.spotify.com/documentation/web-api}},
	year = {},
	note = {[Accessed 31-10-2023]},
}


@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@ARTICLE{LSTM_paper,
  author={Hochreiter, Sepp and Schmidhuber, Jürgen},
  journal={Neural Computation}, 
  title={Long Short-Term Memory}, 
  year={1997},
  volume={9},
  number={8},
  pages={1735-1780},
  doi={10.1162/neco.1997.9.8.1735}}


@misc{spotifyGeneratePopular,
	author = {},
	title = {{H}ow we generate popular tracks - {S}potify --- support.spotify.com},
	howpublished = {\url{https://support.spotify.com/us/artists/article/how-we-generate-popular-tracks/}},
	year = {},
	note = {[Accessed 31-10-2023]},
}

@INPROCEEDINGS{SpotiPred,
  author={Gulmatico, Joshua S. and Susa, Julie Ann B. and Malbog, Mon Arjay F. and Acoba, Aimee and Nipas, Marte D. and Mindoro, Jennalyn N.},
  booktitle={2022 Second International Conference on Power, Control and Computing Technologies (ICPC2T)}, 
  title={SpotiPred: A Machine Learning Approach Prediction of Spotify Music Popularity by Audio Features}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICPC2T53885.2022.9776765}}

@article{LSTM_Random_Forest,
  title={Music trend prediction based on improved LSTM and random forest algorithm},
  author={Liu, Xiangli},
  journal={Journal of Sensors},
  volume={2022},
  pages={1--10},
  year={2022},
  publisher={Hindawi Limited}
}

@INPROCEEDINGS{LSTM_Wang,
  author={Wang, Zhenye and Ye, Chengxu and Wang, Wentao},
  booktitle={2019 4th International Conference on Computational Intelligence and Applications (ICCIA)}, 
  title={Music Trend Forecast Based on LSTM}, 
  year={2019},
  volume={},
  number={},
  pages={30-35},
  doi={10.1109/ICCIA.2019.00013}}


@InProceedings{sharmaSongPopularity,
author="Sharma, Dolly
and Khetarpaul, Sonia
and Mohit Kumar, S.
and Parthasarathy, Ambreesh
and Agarwalla, Sparsh",
editor="Hua, Wen
and Wang, Hua
and Li, Lei",
title="Performance Prediction of Songs on Online Music Platforms",
booktitle="Databases Theory and Applications",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="209--216",
isbn="978-3-031-15512-3"
}

@article{GridSearchDoE,
title = {Design of experiments and focused grid search for neural network parameter optimization},
journal = {Neurocomputing},
volume = {186},
pages = {22-34},
year = {2016},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.12.061},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215020184},
author = {F.J. Pontes and G.F. Amorim and P.P. Balestrassi and A.P. Paiva and J.R. Ferreira},
keywords = {Design of Experiment, Focused Grid Search, Artificial Neural Network, Machining, Tuning},
abstract = {The present work offers some contributions to the area of surface roughness modeling by Artificial Neural Networks (ANNs) in machining processes. It proposes a method for an optimized project of a Multi-Layer Perceptron (MLP) network architecture applied for the prediction of Average Surface Roughness (Ra). The tuning method is expressed in the format of an algorithm employing two techniques from Design of Experiments (DOE) methodology: Full factorials and Evolutionary Operations (EVOP). Datasets retrieved from literature are employed to form training and test data sets for the ANN. The proposed tuning method leads to significant reduction of roughness prediction errors in machining operations in comparison to techniques currently used. It constitutes an effective option for the systematic design models based on ANN for prediction of surface roughness, filling the gap reported in the literature on this subject.}
}

@article{TikTok,
  title={The Influence of TikTok: Promotion Trends in Mainstream Pop Music},
  author={Jorgenson, Lexie},
  year={2022}
}

@misc{NNcancomputeanyfunction,
  author = {Nielsen, Michael A.},
  publisher = {Determination Press},
  title = {Neural Networks and Deep Learning},
  url = {http://neuralnetworksanddeeplearning.com/},
  year = {2015},
  chapter = {4},
  note = {[Accessed 17-11-2023]},
}

@article{LSTMtodealwithmissingdata,
title = {LSTM-based traffic flow prediction with missing data},
journal = {Neurocomputing},
volume = {318},
pages = {297-305},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.08.067},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218310294},
author = {Yan Tian and Kaili Zhang and Jianyuan Li and Xianxuan Lin and Bailin Yang},
keywords = {Traffic flow prediction, Intelligent transportation systems, Deep learning, LSTM},
abstract = {Traffic flow prediction plays a key role in intelligent transportation systems. However, since traffic sensors are typically manually controlled, traffic flow data with varying length, irregular sampling and missing data are difficult to exploit effectively. To overcome this problem, we propose a novel approach that is based on Long Short-Term Memory (LSTM) in this paper. In addition, the multiscale temporal smoothing is employed to infer lost data and the prediction residual is learned by our approach. We demonstrate the performance of our approach on both the Caltrans Performance Measurement System (PeMS) data set and our own traffic flow data set. According to the experimental results, our approach obtains higher accuracy in traffic flow prediction compared with other approaches.}
}

@article{LSTMwithmissingdataICU,
  title={Deep learning to attend to risk in ICU},
  author={Nguyen, Phuoc and Tran, Truyen and Venkatesh, Svetha},
  journal={arXiv preprint arXiv:1707.05010},
  year={2017}
}

@article{ROC-AUC,
  title={A simple generalisation of the area under the ROC curve for multiple class classification problems},
  author={Hand, David J and Till, Robert J},
  journal={Machine learning},
  volume={45},
  pages={171--186},
  year={2001},
  publisher={Springer}
}

@article{ARIMA,
  title={Time series forecasting using a hybrid ARIMA and neural network model},
  author={Zhang, G Peter},
  journal={Neurocomputing},
  volume={50},
  pages={159--175},
  year={2003},
  publisher={Elsevier}
}

@INPROCEEDINGS{LSTM_other_optimisers,
  author={Chang, Zihan and Zhang, Yang and Chen, Wenbo},
  booktitle={2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS)}, 
  title={Effective Adam-Optimized LSTM Neural Network for Electricity Price Forecasting}, 
  year={2018},
  volume={},
  number={},
  pages={245-248},
  abstract={Electrical energy, considered to be a clean energy source, has made a significant contribution to humanity. To make better use of electric energy, great efforts have been paid by electricity market researchers and practitioners on electricity price forecasting. Long short-term memory (LSTM), a type of recurrent neural network, performs well in many areas, such as language modeling and speech recognition. However, the performance of applying the LSTM model to process time series and nonlinear regression problems is not so satisfactory. Stochastic gradient-based optimization has core practical importance in many scientific and engineering fields. Adam, a method for efficient stochastic optimization, has combined the advantages of two popular optimization methods: AdaGrad and RMSProp, it makes LSTM model perform even better. In this study, two examples were listed to verify the performance of the Adam-optimized LSTM neural network, and the dataset from New South Wales of Australia were adopted to illustrate the excellence of model. The results show that the proposed model can significantly improve the prediction accuracy.},
  keywords={},
  doi={10.1109/ICSESS.2018.8663710},
  ISSN={2327-0594},
  month={Nov},}


@article{original_LSTM,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
journal = {Neural Comput.},
month = {nov},
pages = {1735–1780},
numpages = {46}
}

@misc{tensorflowTimeSeries,
	author = {},
	title = {{T}ime series forecasting  |  {T}ensor{F}low {C}ore - tensorflow.org},
	howpublished = {\url{https://www.tensorflow.org/tutorials/structured_data/time_series#single-shot_models}},
	year = {},
	note = {[Accessed 2-11-2023]},
}

@misc{TF_Dense,
	author = {},
	title = {tf.keras.layers.{D}ense  |  {T}ensor{F}low v2.14.0 - tensorflow.org},
	howpublished = {\url{https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense}},
	year = {},
	note = {[Accessed 2-11-2023]},
}

@misc{TF_LSTM,
	author = {},
	title = {tf.keras.layers.{L}{S}{T}{M}  |  {T}ensor{F}low v2.14.0 - tensorflow.org},
	howpublished = {\url{https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM}},
	year = {},
	note = {[Accessed 2-11-2023]},
}